{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T8Er2XzYzFy"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1uPBnYRZFHj"
      },
      "source": [
        "## Clone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fP_tPt_GuMI2",
        "outputId": "835b1684-033e-493c-b577-cec9b0ba6489"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'grpo_chess'...\n",
            "remote: Enumerating objects: 715, done.\u001b[K\n",
            "remote: Counting objects: 100% (357/357), done.\u001b[K\n",
            "remote: Compressing objects: 100% (248/248), done.\u001b[K\n",
            "remote: Total 715 (delta 176), reused 243 (delta 107), pack-reused 358 (from 1)\u001b[K\n",
            "Receiving objects: 100% (715/715), 376.74 KiB | 22.16 MiB/s, done.\n",
            "Resolving deltas: 100% (424/424), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/noamdwc/grpo_chess.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q8mqJFy3H9u",
        "outputId": "688e81c7-b8dd-4231-cab7-4259093103a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access 'src': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBpvmm0Mvlvn",
        "outputId": "cd40e94f-0bc3-4955-e8dd-eac4299babd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/grpo_chess\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "REPO_PATH = '/content/grpo_chess'\n",
        "sys.path.append(REPO_PATH)\n",
        "%cd {REPO_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0x9qEEyuvzjE",
        "outputId": "a28e4b84-3ceb-42e3-9eb3-beb0b3d38049"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Branch 'self_play' set up to track remote branch 'self_play' from 'origin'.\n",
            "Switched to a new branch 'self_play'\n"
          ]
        }
      ],
      "source": [
        "!git checkout self_play"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utZ0Uv4EvgUi",
        "outputId": "5e2f9e2a-80d3-4877-9db0-2334e3d5ca72"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m176.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m108.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.5/849.5 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -q pytorch_lightning wandb python-chess jaxtyping datasets huggingface_hub # The tokenization from searchless_chess require jaxtyping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFzyzY-ozGwP",
        "outputId": "cc22a193-d365-40e8-95df-715e1ed32b6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/grpo_chess/src\n",
            "Fetching 19 files:   0% 0/19 [00:00<?, ?it/s]\n",
            ".gitattributes: 1.52kB [00:00, 4.15MB/s]\n",
            "Fetching 19 files:   5% 1/19 [00:00<00:05,  3.18it/s]\n",
            "README.md: 5.16kB [00:00, 14.7MB/s]\n",
            "\n",
            "config.json: 100% 187/187 [00:00<00:00, 1.97MB/s]\n",
            "Fetching 19 files:  16% 3/19 [00:00<00:02,  6.83it/s]\n",
            "__init__.py: 100% 31.0/31.0 [00:00<00:00, 428kB/s]\n",
            "\n",
            "config.cpython-310.pyc: 100% 1.83k/1.83k [00:00<00:00, 21.1MB/s]\n",
            "\n",
            "model_info.json: 100% 233/233 [00:00<00:00, 2.89MB/s]\n",
            "Fetching 19 files:  21% 4/19 [00:00<00:02,  7.06it/s]\n",
            "constants.cpython-310.pyc: 100% 3.57k/3.57k [00:00<00:00, 44.1MB/s]\n",
            "\n",
            "hf_model.cpython-310.pyc: 100% 9.00k/9.00k [00:00<00:00, 57.2MB/s]\n",
            "\n",
            "params.npz:   0% 0.00/35.8M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "tokenizer.cpython-310.pyc: 100% 2.22k/2.22k [00:00<00:00, 19.3MB/s]\n",
            "\n",
            "\n",
            "transformer.cpython-310.pyc: 100% 7.80k/7.80k [00:00<00:00, 64.2MB/s]\n",
            "\n",
            "\n",
            "utils.cpython-310.pyc: 100% 4.20k/4.20k [00:00<00:00, 31.9MB/s]\n",
            "\n",
            "\n",
            "constants.py: 3.34kB [00:00, 19.7MB/s]\n",
            "\n",
            "\n",
            "hf_model.py: 11.6kB [00:00, 37.9MB/s]\n",
            "\n",
            "\n",
            "transformer.py: 9.65kB [00:00, 34.5MB/s]\n",
            "\n",
            "\n",
            "tokenizer.py: 3.20kB [00:00, 19.4MB/s]\n",
            "\n",
            "\n",
            "config.py: 3.13kB [00:00, 18.5MB/s]\n",
            "\n",
            "\n",
            "utils.py: 5.37kB [00:00, 20.2MB/s]\n",
            "\n",
            "\n",
            "tree_structure.pkl:   0% 0.00/4.94k [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "params.npz: 100% 35.8M/35.8M [00:01<00:00, 22.0MB/s]\n",
            "Fetching 19 files:  26% 5/19 [00:02<00:09,  1.51it/s]\n",
            "\n",
            "tree_structure.pkl: 100% 4.94k/4.94k [00:01<00:00, 3.95kB/s]\n",
            "Fetching 19 files: 100% 19/19 [00:02<00:00,  7.20it/s]\n",
            "Model downloaded to: /content/grpo_chess/src/searchless_chess_model\n",
            "/content/grpo_chess\n"
          ]
        }
      ],
      "source": [
        "%cd src\n",
        "!python ../pull_searchelss_chess_model.py\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgIM4blVZBqB"
      },
      "source": [
        "## Reload"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6RQLSasZUxj"
      },
      "source": [
        "Since `%autoreload` is unavailable, you can use `importlib.reload` to update modules after modifying their code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kczoEfEWii_R",
        "outputId": "6fca7172-ff13-42a5-e58e-2c3bf15a128a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 11, done.\u001b[K\n",
            "remote: Counting objects:   9% (1/11)\u001b[K\rremote: Counting objects:  18% (2/11)\u001b[K\rremote: Counting objects:  27% (3/11)\u001b[K\rremote: Counting objects:  36% (4/11)\u001b[K\rremote: Counting objects:  45% (5/11)\u001b[K\rremote: Counting objects:  54% (6/11)\u001b[K\rremote: Counting objects:  63% (7/11)\u001b[K\rremote: Counting objects:  72% (8/11)\u001b[K\rremote: Counting objects:  81% (9/11)\u001b[K\rremote: Counting objects:  90% (10/11)\u001b[K\rremote: Counting objects: 100% (11/11)\u001b[K\rremote: Counting objects: 100% (11/11), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 6 (delta 4), reused 6 (delta 4), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  16% (1/6)\rUnpacking objects:  33% (2/6)\rUnpacking objects:  50% (3/6)\rUnpacking objects:  66% (4/6)\rUnpacking objects:  83% (5/6)\rUnpacking objects: 100% (6/6)\rUnpacking objects: 100% (6/6), 530 bytes | 265.00 KiB/s, done.\n",
            "From https://github.com/noamdwc/grpo_chess\n",
            "   a50bca9..c349968  self_play  -> origin/self_play\n",
            "Updating a50bca9..c349968\n",
            "Fast-forward\n",
            " src/grpo_logic/model.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5DMweVAhZBfg",
        "outputId": "e4c128a3-8a97-463e-e094-f0151265947e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<module 'src' from '/content/grpo_chess/src/__init__.py'>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import importlib\n",
        "import src\n",
        "\n",
        "# # After modifying the code in the file, run this to reload the module:\n",
        "importlib.reload(src)\n",
        "# # If you use 'from ... import ...', you may need to re-run the import line as well:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MGrvYz2Hchw"
      },
      "source": [
        "## After Session Restart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibR9NI0qHcYR",
        "outputId": "cf095656-4f68-424d-8ae9-3582ba584999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/grpo_chess\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "REPO_PATH = '/content/grpo_chess'\n",
        "sys.path.append(REPO_PATH)\n",
        "%cd {REPO_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysix7IF2nONS"
      },
      "source": [
        "# Run code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLnFm-X62L8b"
      },
      "source": [
        "## Train Script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cvZhGky2Lws",
        "outputId": "bf3eb21c-4ad0-47e3-d265-cddd8b64c5ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login $(cat ../drive/MyDrive/wandb/key.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_xE3YSH2Li6"
      },
      "outputs": [],
      "source": [
        "!apt-get -qq install -y stockfish # Download stockfish"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7q0r0Izf2Trf"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from src.trainer import get_trainer\n",
        "from src.chess.boards_dataset import ChessStartStatesDataset\n",
        "from src.grpo_logic.model import GRPOChessTransformer\n",
        "from src.configs.config_loader import load_experiment_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkrr71ht2Tht"
      },
      "outputs": [],
      "source": [
        "DEFALT_CONFIG_PATH = '/content/grpo_chess/src/configs/default.yaml'\n",
        "OVERRIDE_CONFIGS = {'pretrain': {'checkpoint_path': '/content/drive/MyDrive/data/grpo-chess/pretrain_checkpoints/pretrain-20260128-1215-16es-epoch=12-train/loss=2.3285.ckpt'}}\n",
        "config = load_experiment_config(DEFALT_CONFIG_PATH, overrides=OVERRIDE_CONFIGS)\n",
        "dataloader_config = {\n",
        "        \"batch_size\": config.training.batch_size,\n",
        "        \"num_workers\": 2,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "X5xgAN7x2t-B",
        "outputId": "420fcae8-c478-4f95-bb53-fb21b8a8ac62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generated run name: chess-grpo-20260128-1822-xgsr\n",
            "Loading pretrained weights from: /content/drive/MyDrive/data/grpo-chess/pretrain_checkpoints/pretrain-20260128-1215-16es-epoch=12-train/loss=2.3285.ckpt\n"
          ]
        },
        {
          "ename": "UnpicklingError",
          "evalue": "Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL src.models.ChessTransformerConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([src.models.ChessTransformerConfig])` or the `torch.serialization.safe_globals([src.models.ChessTransformerConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2399953303.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChessStartStatesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdataloader_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m model = GRPOChessTransformer(\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mtransformer_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mgrpo_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrpo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/grpo_chess/src/grpo_logic/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, transformer_config, grpo_config, eval_cfg, stockfish_cfg, policy_cfg, searcher_cfg, pretrain_cfg)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;31m# Load pretrained weights if specified\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpretrain_cfg\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpretrain_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrain_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sync_old_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/grpo_chess/src/grpo_logic/model.py\u001b[0m in \u001b[0;36m_load_pretrained_weights\u001b[0;34m(self, pretrain_cfg)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading pretrained weights from: {checkpoint_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m         \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m         \u001b[0;31m# Handle different checkpoint formats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1527\u001b[0m                         )\n\u001b[1;32m   1528\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpicklingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_wo_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1530\u001b[0m                 return _load(\n\u001b[1;32m   1531\u001b[0m                     \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnpicklingError\u001b[0m: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n\tWeightsUnpickler error: Unsupported global: GLOBAL src.models.ChessTransformerConfig was not an allowed global by default. Please use `torch.serialization.add_safe_globals([src.models.ChessTransformerConfig])` or the `torch.serialization.safe_globals([src.models.ChessTransformerConfig])` context manager to allowlist this global if you trust this class/function.\n\nCheck the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html."
          ]
        }
      ],
      "source": [
        "trainer = get_trainer(num_epochs=config.training.num_epochs)\n",
        "dataset = ChessStartStatesDataset(config.dataset)\n",
        "dataloader = DataLoader(dataset, **dataloader_config)\n",
        "model = GRPOChessTransformer(\n",
        "        transformer_config=config.transformer,\n",
        "        grpo_config=config.grpo,\n",
        "        eval_cfg=config.eval,\n",
        "        stockfish_cfg=config.stockfish,\n",
        "        policy_cfg=config.policy,\n",
        "        searcher_cfg=config.searcher,\n",
        "        pretrain_cfg=config.pretrain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AxqmDqQY28QR"
      },
      "outputs": [],
      "source": [
        "print(\"Starting Training with WandB Tracking...\")\n",
        "try:\n",
        "  trainer.fit(model, dataloader)\n",
        "except Exception as e:\n",
        "  print(e)\n",
        "  with open('/content/drive/MyDrive/data/grpo-chess/error.txt', 'w') as f:\n",
        "    f.write(str(e))\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnkqVUFonbf3"
      },
      "source": [
        "## Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76NJZCuM4d3P"
      },
      "outputs": [],
      "source": [
        "PRETRAIN_DATASET_CACHE_DIR = '/content/drive/MyDrive/data/grpo-chess/pretrain_processed_dataset_5m'\n",
        "OVERRIDE_CONFIGS = {'dataset': {'cache_path': PRETRAIN_DATASET_CACHE_DIR, 'max_samples': int(5e6)},\n",
        "                    'pretrain': {'checkpoint_dir': '/content/drive/MyDrive/data/grpo-chess/pretrain_checkpoints'}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeQCKo2mnbV2",
        "outputId": "e4240149-1a44-4484-d2d3-25b4a7f52a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: [wandb.login()] Using explicit session credentials for https://api.wandb.ai.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ],
      "source": [
        "!wandb login $(cat ../drive/MyDrive/wandb/key.txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghkIpmw3nxfK"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import random\n",
        "import string\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from src.pretrain.pretrain import (load_pretrain_config,\n",
        "                                                  train,\n",
        "                                                  PretrainChessTransformer,\n",
        "                                                  get_pretrain_trainer,\n",
        "                                                  collate_pretrain_batch,\n",
        "                                                  ChessPretrainDataset,\n",
        "                                                  PretrainDatasetConfig\n",
        "                                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYZ_Y3GZnbTo"
      },
      "outputs": [],
      "source": [
        "pretrain_config, dataset_config, transformer_config = load_pretrain_config(overrides=OVERRIDE_CONFIGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0RWmKWHD7VT"
      },
      "outputs": [],
      "source": [
        "!cp {dataset_config.cache_path}/*.pt /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRzjEt6XDs28"
      },
      "outputs": [],
      "source": [
        "dataset_config.cache_path = '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Ic7gv4nSopYg",
        "outputId": "9e27da5e-8297-4713-8814-9d6c900754ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Epoch 11/21 <span style=\"color: #6206e0; text-decoration-color: #6206e0\">━━━━━━━━━━╸</span><span style=\"color: #3a3a3a; text-decoration-color: #3a3a3a\">━━━━━━━━━━━━━━━━━━━━━</span> 405/1221 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">0:05:41 • 0:11:07</span> <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f; text-decoration: underline\">1.23it/s</span> <span style=\"font-style: italic\">v_num: 1vv0 train/loss: 2.365     </span>\n",
              "                                                                                 <span style=\"font-style: italic\">train/accuracy: 0.370 val/loss:   </span>\n",
              "                                                                                 <span style=\"font-style: italic\">2.412 val/accuracy: 0.364         </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Epoch 11/21 \u001b[38;2;98;6;224m━━━━━━━━━━\u001b[0m\u001b[38;2;98;6;224m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m 405/1221 \u001b[2m0:05:41 • 0:11:07\u001b[0m \u001b[2;4m1.23it/s\u001b[0m \u001b[3mv_num: 1vv0 train/loss: 2.365     \u001b[0m\n",
              "                                                                                 \u001b[3mtrain/accuracy: 0.370 val/loss:   \u001b[0m\n",
              "                                                                                 \u001b[3m2.412 val/accuracy: 0.364         \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "train(pretrain_config, dataset_config, transformer_config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "D1uPBnYRZFHj",
        "ZgIM4blVZBqB",
        "0MGrvYz2Hchw"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
