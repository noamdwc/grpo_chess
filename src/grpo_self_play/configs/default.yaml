# Default experiment configuration
# This file contains all hyperparameters for a training run.
# Copy this file and modify for new experiments.

# =============================================================================
# Training Loop Settings
# =============================================================================
training:
  num_epochs: 400
  batch_size: 32
  steps_per_epoch: 512

# =============================================================================
# GRPO (Group Relative Policy Optimization) Config
# =============================================================================
grpo:
  lr: 0.00003
  num_trajectories: 16
  trajectory_depth: 16
  clip_ratio: 0.10
  kl_coef: 0.01  # initial value for KL penalty
  entropy_coef: 0.10  # initial value for entropy bonus
  eval_every_n_epochs: 10
  ppo_steps: 4
  rollout_temperature: 1.5  # >1 increases exploration during rollouts

  # Unified Entropy Recovery
  # Coordinates entropy_coef boost, kl_coef reduction, and temperature increase
  # to recover from entropy collapse. Stops training if entropy hits critical level.
  use_entropy_recovery: true
  entropy_floor: 1.5  # trigger recovery when entropy stays below this
  entropy_critical: 0.5  # hard stop if entropy drops below this
  entropy_floor_steps: 100  # consecutive steps below floor before recovery
  critical_steps_threshold: 50  # consecutive steps below critical before stop
  entropy_boost_factor: 1.5  # multiply entropy_coef by this on recovery
  max_entropy_coef: 1.5  # cap for entropy_coef after boosts
  kl_reduction_factor: 0.5  # multiply kl_coef by this on recovery (escape KL trap)
  min_kl_coef: 0.0  # allow kl_coef to go to zero during recovery
  temperature_boost: 0.2  # add this to temperature on recovery
  max_temperature: 2.5  # cap for temperature after boosts

# =============================================================================
# Transformer Model Config
# =============================================================================
transformer:
  vocab_size: 300
  embed_dim: 256
  num_layers: 4
  num_heads: 8
  action_dim: 1968

# =============================================================================
# Evaluation Config (vs Stockfish)
# =============================================================================
eval:
  games: 32
  seed: 0
  max_plies: 400
  randomize_opening: true
  opening_plies: 6

# =============================================================================
# Stockfish Config
# =============================================================================
stockfish:
  path: "/usr/games/stockfish"  # Override in colab/local as needed
  skill_level: 2
  use_elo_limit: false
  elo: 2500
  movetime_ms: 50
  threads: 1
  hash_mb: 128

# =============================================================================
# Policy Player Config (for evaluation)
# =============================================================================
policy:
  temperature: 0.8
  greedy: true
  branching_factor: 4
  search_depth: 2

# =============================================================================
# Searcher Config (optional - set to null to disable)
# =============================================================================
searcher: null
# searcher:
#   n_trajectories: 4
#   trajectory_depth: 8

# =============================================================================
# Pretraining (optional - load pretrained weights before GRPO)
# =============================================================================
pretrain:
  checkpoint_path: null  # Path to pretrained checkpoint (e.g., "checkpoints/pretrain/pretrain_final.pt")
  freeze_layers: 0       # Number of transformer layers to freeze (0 = train all)

# =============================================================================
# Dataset Config (Chess Start States)
# =============================================================================
dataset:
  max_steps: 512  # Should match steps_per_epoch
  phase_distribution:
    opening: 0.33
    middlegame: 0.34
    endgame: 0.33
  min_eval_cp: -200
  max_eval_cp: 200
  quality_filter: true
  stockfish_filter_depth: 4
